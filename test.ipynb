{"nbformat":4,"nbformat_minor":5,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"},"colab":{"name":"test.ipynb","provenance":[],"collapsed_sections":[]},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"ab405b46"},"source":["import torch\n","from torch.utils.data import Dataset, DataLoader\n","from torchvision.io import read_image\n","from torchvision.transforms import ToTensor, Lambda, Normalize, CenterCrop, Resize\n","from torch import nn\n","\n","from glob import glob\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import pandas as pd\n","import csv"],"id":"ab405b46","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-Obnzw-W6h3B"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"id":"-Obnzw-W6h3B","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0oCzSQ_E6h0k"},"source":["cd drive/MyDrive/"],"id":"0oCzSQ_E6h0k","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"S0lv-b7O6_--"},"source":["ls"],"id":"S0lv-b7O6_--","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YahEcUXZ6hxs"},"source":["!pip install import-ipynb\n","import import_ipynb"],"id":"YahEcUXZ6hxs","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zXp3KxZu6wj-"},"source":["from Custom_Read_Data import CustomReadData\n","from Custom_image_dataset import CustomImageDataset\n","from Train import Model_Training\n","import densenet \n","import vgg_net\n","import resnet\n","import Inception_V3"],"id":"zXp3KxZu6wj-","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5hfaOMm96whM"},"source":["#CUDA for Pytorch\n","use_cuda = torch.cuda.is_available()\n","device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n","#device = 'cpu'\n","print(f'using {device} device')\n","#torch.backends.cudnn.benchmark = True"],"id":"5hfaOMm96whM","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tEL5ZiG56wZb"},"source":["model = resnet.ResNet182(img_channel=3, num_classes=3)\n","model.to(device)"],"id":"tEL5ZiG56wZb","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3a5565aa"},"source":["PATH = './res_net182.pth'\n","\n","model.load_state_dict(torch.load(PATH))"],"id":"3a5565aa","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9f20b508"},"source":["test_path = './test/'\n","\n","files = glob(test_path + '*/*_image.jpg')\n","\n","outfile = open('predictions_resnet_182.csv', 'w')\n","\n","outfile.write(\"guid/image,label\\n\")\n","\n","with torch.no_grad():\n","    for f in files:\n","        x = read_image(f)\n","        x = Resize((400, 800))(x)\n","        \n","        x = Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))(x.type(torch.float)) #Need to use the proper mean and std of the image planes\n","        x_shape = list(x.size())\n","        x = x.reshape((1, x_shape[0], x_shape[1], x_shape[2]))\n","        x = x.to(device)\n","        output = model(x)\n","        output = output.cpu().detach().numpy()\n","        out = np.argmax(output)\n","        print(out)\n","        \n","        f_split = f.split(\"/\")     \n","        folder = f_split[2]    #check this line \"\\\\\" if error occurs and check the index values\n","        img_name = f_split[3].split(\"_\")[0]\n","        file_name = folder + '/' + img_name\n","        \n","        outfile.write(f\"{file_name},{out}\\n\")\n","\n","outfile.close()"],"id":"9f20b508","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZF6FoxMsC5-l"},"source":["#Optional method\n","#Load model using checkpoint\n","\n","loaded_checkpoint = torch.load(\"./checkpoints_resnet_182.pth\")\n","epoch = loaded_checkpoint[\"epoch\"]\n","print(epoch)\n","\n","model = resnet.ResNet182(img_channel=3, num_classes=3)\n","model.to(device)\n","\n","learning_rate = 1e-3\n","optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n","\n","model.load_state_dict(loaded_checkpoint[\"model_state\"])\n","optimizer.load_state_dict(loaded_checkpoint[\"optim_state\"])"],"id":"ZF6FoxMsC5-l","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"aWfInJNEDJW2"},"source":[""],"id":"aWfInJNEDJW2","execution_count":null,"outputs":[]}]}